{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:cornflowerblue\">Criando os Primeiros Prompts</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Para saber mais: compreendendo as limitações do ChatGPT - Por que nem sempre as respostas são precisas?</h2>\n",
    "<p>\n",
    "É uma forma de solicitar ao modelo que produza uma resposta ou texto relevante com base na informação fornecida. Os prompts desempenham um papel crucial na interação com o modelo, permitindo que os usuários forneçam direcionamentos específicos para as respostas que desejam obter.<br>\n",
    "<br>\n",
    "Mas por que os resultados dos prompts nem sempre são bons?<br>\n",
    "<br>\n",
    "Segundo, a OpenAI o ChatGPT possui algumas limitações:<br>\n",
    "<br>\n",
    "Às vezes, o ChatGPT escreve respostas plausíveis, mas incorretas ou sem sentido. Isso ocorre porque o modelo é treinado com base em grandes quantidades de texto da internet, mas nem todas as informações nesses dados são precisas. Portanto, o modelo pode ocasionalmente produzir respostas incorretas ou inventar informações.<br>\n",
    "O ChatGPT também é sensível a ajustes nos prompts ou às tentativas da mesma solicitação várias vezes. Por exemplo, você pode escrever algo e o modelo pode afirmar que não sabe a resposta, mas se você fizer alguma reformulação no prompt a resposta pode vir de forma correta. Ou se você utilizar o mesmo prompt várias vezes as respostas podem não ser consistentes.<br>\n",
    "O modelo também pode ser prolixo e usar demais certas frases. Esses problemas surgem de viéses nos dados de treinamento e problemas de super otimização.<br>\n",
    "Além disso, o ChatGPT tem limitações em sua capacidade de memória e contexto. O modelo leva em consideração apenas uma quantidade limitada de texto anterior ao gerar uma resposta. Isso significa que se a tarefa exigir informações ou referências anteriores específicas, o modelo pode não conseguir acessá-las adequadamente. Isso pode levar a respostas inconsistentes ou que parecem ignorar completamente o histórico da conversa.<br>\n",
    "<br>\n",
    "Por fim, o modelo pode sofrer com problemas de viés e gerar respostas que podem ser imprecisas e tendenciosas, devido à natureza dos dados de treinamento usados e à maneira como eles foram coletados.<br>\n",
    "<br>\n",
    "Por isso, é fundamental que ao utilizar o ChatGPT, sejam adotadas estratégias que maximizem o potencial do modelo e garantam resultados mais precisos e confiáveis. Neste curso, você irá aprender algumas dessas estratégias e poderá utilizá-las na sua interação com o ChatGPT para obter respostas mais adequadas e relevantes para as suas necessidades.<br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Utilizando diferentes estratégias para criar prompts</h2>\n",
    "<p>\n",
    "Algumas estratégias para se comunicar com o ChatGPT:<br>\n",
    "<li>Falar o que precisa, ordenar: \"Eu quero que, eu preciso, me dê\";\n",
    "<li>Completar a frase, fazer uma conclusão: \"Curso básico de python...\";\n",
    "<li>Demonstrar com exemplos: \"Exemplo: Análise de dados para detectar anomalias médicas.Resposta: Revolucionando a medicina moderna com análise de dados e salvando vidas\";<br>\n",
    "<br>\n",
    "Em todos os casos deve ser adicionadas informações para contexto do que se está sendo pedido.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Para saber mais: entendendo o que são tokens</h2>\n",
    "<p>\n",
    "Já deu pra notar que projetar seu prompt é essencialmente como você “programa” o modelo, geralmente fornecendo algumas instruções ou alguns exemplos. Mas como esse modelo funciona? Como ele sabe o que vai nos responder?<br>\n",
    "<br>\n",
    "Os modelos entendem e processam o texto dividindo-o em tokens. Um token pode ser uma palavra individual, um caractere, ou até mesmo uma parte de uma palavra. Por exemplo, a frase “Hello World!” teria os seguintes tokens:<br>\n",
    "<li>\"Hello\"\n",
    "<li>\" world\"\n",
    "<li>\"!\"<br>\n",
    "<br>\n",
    "Enquanto isso, essa mesma frase em português (\"Olá mundo!\"), seria dividida da seguinte forma:\n",
    "<li>\"Ol,\"\n",
    "<li>\"á,\"\n",
    "<li>\"mund,\"\n",
    "<li>\"o\"\n",
    "<li>\"!\"<br>\n",
    "<br>\n",
    "Com isso, é possível verificar que dependendo do idioma o processo de tokenização divide as palavras de forma diferente.<br>\n",
    "<br>\n",
    "Se você tiver curiosidade em checar como um texto se traduz em tokens, existe uma ferramenta da OpenAI chamada tokenizer.<br>\n",
    "<br>\n",
    "O modelo do ChatGPT atribui um valor de representação a cada token, capturando informações contextuais e semânticas. Essas informações semânticas referem-se ao significado e à interpretação das palavras, frases ou sentenças em um contexto específico.<br>\n",
    "<br>\n",
    "A semântica está relacionada ao estudo do significado das palavras e como elas se combinam para formar ideias e expressões mais complexas.<br>\n",
    "<br>\n",
    "No contexto do processamento de linguagem natural, as informações semânticas são usadas para capturar o significado e a intenção subjacentes a uma sequência de palavras. Ao entender as informações semânticas, um modelo de linguagem como o ChatGPT pode inferir o contexto e responder de maneira mais precisa.<br>\n",
    "<br>\n",
    "Então, os tokens de entrada são passados sequencialmente pelo modelo, permitindo que ele analise o contexto anterior para gerar previsões sobre o próximo token.<br>\n",
    "<br>\n",
    "É importante mencionar que o número de tokens de entrada é limitado para garantir o bom desempenho do modelo e controlar os custos computacionais. Se um prompt exceder o limite de tokens permitido, será necessário reduzi-lo ou dividir em partes para se adequar ao limite.\n",
    "<br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:cornflowerblue\">Melhorando a Confiabilidade dos Resultados</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Dividindo tarefas complexas em subtarefas mais simples</h2>\n",
    "<p>\n",
    "<li>Evitar prompts subjetivos e amplos, como por exemplo:<br>\n",
    "Prompt: Estou lançando uma campanha nova de natal para um novo produto na nossa plataforma de assinatura de supermercado, \"o mercado de frutas da temporada\" no youtube. Sugira tudo que eu preciso para criar uma ótima campanha.<br>\n",
    "<br>\n",
    "\n",
    "<li>O texto é genérico e pode tarzer diversos resutados. Se for necessária automação, ele não serve para nada. Ao invés disso:<br>\n",
    "Prompt: Estou lançando uma campanha nova de natal para um novo produto na nossa plataforma de assinatura de supermercado, \"o mercado de frutas da temporada\" no youtube. Sugira tudo que eu preciso para criar uma ótima campanha. O vídeo no youtube precisa do título, descrição, ideia de thumbnail e texto no thumbnail. Sugira a duração em minutos e em quais canais posso fazer parceria para divulgar a campanha. Descreva também os pontos fortes dessa campanha.<br>\n",
    "<br>\n",
    "\n",
    "<li>A resposta fica mais direcionada, mas ainda não é possível automatizar processos. Para isso:<br>\n",
    "Prompt: O vídeo no youtube precisa do título, descrição, ideia de thumbnail e texto no thumbnail. Sugira a duração em minutos e em quais canais posso fazer parceria para divulgar a campanha. Descreva também os pontos fortes dessa campanha.<br>\n",
    "<br>\n",
    "Devolva o resultado em código Javascript:<br>\n",
    "<br>\n",
    "\"\"\"<br>\n",
    "<br>\n",
    "titulo = \"\"<br>\n",
    "<br>\n",
    "ideia_de_thumbnail = \"\"<br>\n",
    "<br>\n",
    "descricao = \"\"<br>\n",
    "<br>\n",
    "duracao = \"\"<br>\n",
    "<br>\n",
    "canais = []<br>\n",
    "<br>\n",
    "pontos_fortes = []<br>\n",
    "<br>\n",
    "\"\"\"<br>\n",
    "<br>\n",
    "\n",
    "Dessa forma o resultado terá um separador que pode ser utilizado para pegar a resposta, separar os itens necessários e automatizar processos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Aprendendo a dar instruções mais claras</h2>\n",
    "<p>\n",
    "O prompttambém pode ser enviado solicitando somente o código, para excluir demais textos. Em cima dessa lógica, podem ser solicitados diversos blocos de código ou objetos de uma determinada linguagem, ou formulário, etc... para \"garantir\" que o resultado é padrão e pode ser facilmente interpretado pela máquina no processo de automação.<br>\n",
    "De modo geral, pode ser solicitado o formado desejado para o retorno do prompt.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Para saber mais: boas práticas na escrita de prompts</h2>\n",
    "<p>\n",
    "Existem algumas dicas de boas práticas que podem te ajudar a melhorar a escrita dos prompts para o ChatGPT. Aqui estão algumas delas:<br>\n",
    "<br>\n",
    "Use delimitadores para indicar claramente partes distintas do prompt:<br>\n",
    "Os delimitadores podem ajudar a escrever prompts melhores no ChatGPT, porque fornecem uma estrutura clara para o modelo entender o que está sendo solicitado e gerar respostas mais precisas e relevantes.<br>\n",
    "<br>\n",
    "O seguintes delimitadores normalmente são utilizados:<br>\n",
    "<br>\n",
    "\n",
    "<li>\"\"\" (três aspas duplas): O uso de três aspas duplas é comum em várias linguagens de programação e serve para indicar um texto que não deve ser processado ou interpretado. No ChatGPT, isso pode ser usado para separar o texto da instrução. Isso ajuda a deixar a intenção da pergunta ou tópico mais clara para o modelo, facilitando a geração de uma resposta.<br>\n",
    "<br>\n",
    "Exemplo:<br>\n",
    "<br>\n",
    "Dê um título para o texto abaixo:<br>\n",
    "<br>\n",
    "Texto:<br>\n",
    "<br>\n",
    "“””Python é uma linguagem de propósito geral de alto nível, multiparadigma, suporta o paradigma orientado a objetos, imperativo, funcional e procedural. Possui tipagem dinâmica e uma de suas principais características é permitir a fácil leitura do código e exigir poucas linhas de código se comparado ao mesmo programa em outras linguagens. “””<br>\n",
    "<br>\n",
    "\n",
    "<li>```(três crases): As três crases são usadas para indicar que o conteúdo entre elas é tratado como um bloco de código.<br>\n",
    "<br>\n",
    "Exemplo:<br>\n",
    "<br>\n",
    "Explique o código abaixo:<br>\n",
    "<br>\n",
    "```<br>\n",
    "for i in range(5):<br>\n",
    "   print(i)<br>\n",
    "```<br>\n",
    "<br>\n",
    "\n",
    "<li>_____ (sublinhados): Os sublinhados podem ser usados para gerar um resultado no formato de formulário. Isso é interessante, caso você queira automatizar o resultado de um prompt e não deseja que o resultado seja em código, apenas em texto.<br>\n",
    "<br>\n",
    "A seguir temos um prompt que utiliza esse recurso:<br>\n",
    "<br>\n",
    "Título: _____<br>\n",
    "Descrição: _____<br>\n",
    "Ideia de thumbnail: _____<br>\n",
    "Texto de thumbnail: _____<br>\n",
    "Duração: _____<br>\n",
    "Canais: _____, _____,_____<br>\n",
    "Pontos fortes: _____,_____,_____<br>\n",
    "<br>\n",
    "\n",
    "<li>Use acentos e caracteres especiais:<br>\n",
    "Se você escrever os prompts em português é interessante usar acentos ou caracteres especiais. Isso pode ajudar o modelo a entender melhor aquilo que você está solicitando.<br>\n",
    "<br>\n",
    "\n",
    "<li>Use sinais de pontuação:<br>\n",
    "É legal usar sinais de pontuação:vírgulas, interrogações e pontos finais, para separar as cláusulas e tornar o prompt mais fácil de ler e entender.<br>\n",
    "<br>\n",
    "Por exemplo, \"Qual é a diferença entre as linguagens Python e R?\" É mais fácil de entender do que \"Qual é a diferença entre as linguagens Python e R\".<br>\n",
    "<br>\n",
    "\n",
    "<li>Use citações:<br>\n",
    "Use aspas para citar trechos de texto relevantes em seu prompt, especialmente se estiver fazendo uma pergunta baseada em uma citação de um texto. Por exemplo:<br>\n",
    "<br>\n",
    "\n",
    "<li>Tenha clareza e especificidade: Ao escrever um prompt, é importante ser claro(a) e específico(a) sobre o que você deseja que o ChatGPT faça. Isso ajuda o modelo a entender exatamente o que você está pedindo e a gerar uma resposta mais precisa. Por isso, é importante evitar usar termos vagos ou ambíguos que possam confundir o modelo.<br>\n",
    "Por exemplo, em vez de escrever \"Me dê informações sobre Python\", tente escrever \"Como é a sintaxe da linguagem de programação Python?\".<br>\n",
    "<br>\n",
    "\n",
    "<li>Forneça contexto:<br>\n",
    "Fornecer informações adicionais ou contexto relevante para o ChatGPT pode ajudar o modelo a entender melhor a pergunta e gerar uma resposta mais precisa. Se você estiver fazendo uma pergunta sobre um tópico específico, você pode fornecer algumas informações básicas sobre esse tópico no prompt.<br>\n",
    "<br>\n",
    "Por exemplo, se você estiver fazendo uma pergunta sobre um erro em um código Python, forneça alguns detalhes básicos sobre o que é aquele código.<br>\n",
    "<br>\n",
    "\n",
    "<li>Evite perguntas complexas:<br>\n",
    "Evite fazer perguntas complexas ou que exijam respostas detalhadas. O ChatGPT funciona melhor quando recebe perguntas simples e diretas. Por isso, tente dividir perguntas complexas em perguntas menores e mais simples.<br>\n",
    "<br>\n",
    "<br>\n",
    "Lembre-se de que essas são apenas algumas dicas e que a escrita dos prompts pode variar dependendo do contexto da pergunta. Tente usar essas dicas como um guia geral para melhorar a qualidade das suas interações com o ChatGPT!\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Maximizando o potencial dos resultados</h2>\n",
    "<p>\n",
    "Dado um prompt que retorna diversos resultados, pode ser solicitado que um novo seja feito, maximizando o potencial de cada resposta anterior.<br>\n",
    "Importante ressaltar que, novamente, pela natureza da tecnologia, quanto mais genérico o pedido, mais ele vai ter que \"chutar\" uma resposta, ao invés de procurar no contexto.<br>\n",
    "Sendo assim, solicitar que seja feita uma análise ANTES de solicitar a resposta pode melhorar o resultado por aumentar o contexto.<br>\n",
    "<br>\n",
    "Também podem ser atribuido pontos para cada característica para melhorar o resultado do prompt.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Utilizando a estratégia Step by step</h2>\n",
    "<p>Utilizar a estratégia de adicionar o \"Let`s think step by step\", ou seja \"Explique passo a passo\" podem trazer informações importantes especialmente se tratando de verificar o insight lógico da resposta do prompt. Um bom guia é seguir as estratégias:\n",
    "<li>Descrição da situação problema;\n",
    "<li>Obter respostas passo a passo;\n",
    "<li>Analise de cada uma das respostas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:cornflowerblue\">Explorando Aplicações</h1>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
